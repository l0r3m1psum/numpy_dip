{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d9fe9-897f-4707-b94e-92be2fb95ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# https://en.wikipedia.org/wiki/PNG\n",
    "# https://github.com/miloyip/svpng/blob/master/svpng.inc\n",
    "def display(A):\n",
    "    if A.ndim != 3 and A.ndim != 2: raise ValueError(\"A.ndim != 3 and A.ndim != 2\")\n",
    "    A = A.astype(numpy.uint8)\n",
    "    import PIL.Image\n",
    "    return PIL.Image.fromarray(A)\n",
    "def check_img1chan(image):\n",
    "    if image.ndim != 2: raise ValueError(\"image.ndim != 2\")\n",
    "def check_img3chan(image):\n",
    "    if image.ndim != 3: return ValueError(\"image.ndim != 3\")\n",
    "    if image.shape[2] != 3: return ValueError(\"image.shape[2] != 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cefffa-b434-4772-8f7d-834c2caf7944",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = numpy.load('lena_gray.npy')\n",
    "display(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d16c1a-a2c6-49f5-a827-92446a09132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cropping & downsize (naive)\n",
    "collage = numpy.concatenate((A[128:384,128:384], A[0:512:2,0:512:2]), axis=1)\n",
    "display(collage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e2b333-fbe9-4338-b8ed-a8c8f0f0bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple rotations\n",
    "D = A[0:512:2,0:512:2]\n",
    "def f0(image): check_img1chan(image); return numpy.flip(image, axis=0)\n",
    "def f1(image): check_img1chan(image); return numpy.flip(image, axis=1)\n",
    "collage1 = numpy.concatenate((D,     D.T,     f0(D),     f0(D).T),     axis=1)\n",
    "collage2 = numpy.concatenate((f1(D), f1(D).T, f0(f1(D)), f0(f1(D)).T), axis=1)\n",
    "collage = numpy.concatenate((collage1, collage2), axis=0)\n",
    "display(collage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90c0a87-3d59-41a4-937d-688139868cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsize (naive)\n",
    "canvas = numpy.zeros((512, 512)).astype(numpy.uint8)\n",
    "canvas[0:512:2,0:512:2] = A[0:512:2,0:512:2]\n",
    "display(canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d679111c-0abe-4e0b-aa86-a740ccb808cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize\n",
    "\n",
    "# https://chao-ji.github.io/jekyll/update/2018/07/19/BilinearResize.html\n",
    "def bilinear_resize(image, shape):\n",
    "    check_img1chan(image)\n",
    "\n",
    "    image_height, image_width = image.shape\n",
    "    new_height, new_width = shape\n",
    "    image = image.ravel()\n",
    "    ratio_y = (image_height-1)/(new_height-1)\n",
    "    ratio_x = (image_width-1)/(new_width-1)\n",
    "    indices_y, indices_x = numpy.divmod(numpy.arange(new_height*new_width), new_width)\n",
    "    scaled_indices_y = ratio_y*indices_y\n",
    "    scaled_indices_x = ratio_x*indices_x\n",
    "    lows_y = numpy.floor(scaled_indices_y).astype(numpy.int64)\n",
    "    highs_y = numpy.ceil(scaled_indices_y).astype(numpy.int64)\n",
    "    lows_x = numpy.floor(scaled_indices_x).astype(numpy.int64)\n",
    "    highs_x = numpy.ceil(scaled_indices_x).astype(numpy.int64)\n",
    "    weights_y = ratio_y*indices_y - lows_y\n",
    "    weights_x = ratio_x*indices_x - lows_x\n",
    "    a = image[lows_y * image_width + lows_x]\n",
    "    b = image[lows_y * image_width + highs_x]\n",
    "    c = image[highs_y * image_width + lows_x]\n",
    "    d = image[highs_y * image_width + highs_x]\n",
    "    new_image = (\n",
    "          a * (1-weights_x) * (1-weights_y)\n",
    "        + b * weights_x * (1-weights_y)\n",
    "        + c * (1-weights_x) * weights_y\n",
    "        + d * weights_x * weights_y\n",
    "    )\n",
    "    return new_image.reshape(new_height, new_width)\n",
    "display(bilinear_resize(A, (600,400)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370b272b-3afd-45bb-a2b5-de348405de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: can I also interpolate to fill the gaps?\n",
    "def coordinates_transform(image, matrix):\n",
    "    check_img1chan(image)\n",
    "    if matrix.shape != (2, 2): raise ValueError(\"image.ndim != 2,2\")\n",
    "\n",
    "    image_height, image_width = image.shape\n",
    "    image_coords = numpy.stack(numpy.divmod(numpy.arange(image_height*image_width), image_width)).T\n",
    "    image_coords_centered = image_coords - numpy.array(image.shape)//2\n",
    "    image_coords_transformed = image_coords_centered@matrix.T\n",
    "\n",
    "    max_index = numpy.argmax(numpy.linalg.norm(image_coords_transformed, axis=0))\n",
    "    canvas_shape = numpy.ceil(numpy.max(numpy.abs(image_coords_transformed), axis=0)).astype(numpy.int64)*2\n",
    "\n",
    "    canvas = numpy.zeros(canvas_shape)\n",
    "    image_coords_canvas = image_coords_transformed.astype(numpy.int64) + canvas_shape//2\n",
    "    canvas[image_coords_canvas[:,0], image_coords_canvas[:,1]] = image.ravel()\n",
    "    return canvas.reshape(canvas_shape)\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Transformation_matrix#Examples_in_2_dimensions\n",
    "# http://datagenetics.com/blog/august32013/index.html\n",
    "angle = 30.\n",
    "cos_theta = numpy.cos(angle)\n",
    "sin_theta = numpy.sin(angle)\n",
    "rot = numpy.array([\n",
    "    [ cos_theta, sin_theta],\n",
    "    [-sin_theta, cos_theta]\n",
    "])\n",
    "identity = numpy.eye(2)\n",
    "stretch = numpy.array([[2,0],[0,1]])\n",
    "\n",
    "# TODO: affine transformations (e.g. perspective)\n",
    "# TODO: alpha compositing\n",
    "\n",
    "display(coordinates_transform(A, rot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa13b6e-bcb5-430c-821a-ebe71e83d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_invert(image): return 1 - image\n",
    "def transform_gamma(image): return image**0.4\n",
    "def transform_threshold(image): return image > 0.5\n",
    "# https://en.wikipedia.org/wiki/Posterization\n",
    "# https://en.wikipedia.org/wiki/Quantization_(image_processing)\n",
    "# https://lettier.github.io/3d-game-shaders-for-beginners/posterization.html\n",
    "def transform_discretize(image): return numpy.floor(image*10)/10\n",
    "\n",
    "def plot_function(f):\n",
    "    x = numpy.linspace(0,1,256)\n",
    "    y = f(x)\n",
    "    plot = y.reshape(-1, 1) < x\n",
    "    plot = numpy.flip(plot, axis=1).T\n",
    "    plot = plot*255\n",
    "    return plot\n",
    "\n",
    "display(numpy.concatenate(\n",
    "    (plot_function(transform_invert),\n",
    "     plot_function(transform_gamma),\n",
    "     plot_function(transform_threshold),\n",
    "     plot_function(transform_discretize),\n",
    "    ), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502e4046-33c0-4242-b080-6e5f3c74e81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intensity_transform(image, transform):\n",
    "    check_img1chan(image)\n",
    "    image_scaled = image/255\n",
    "    image_trans = transform(image_scaled)\n",
    "    return (image_trans*255)\n",
    "    return res\n",
    "\n",
    "display(numpy.concatenate(\n",
    "    (intensity_transform(A, transform_invert),\n",
    "     intensity_transform(A, transform_gamma),\n",
    "     intensity_transform(A, transform_threshold),\n",
    "     intensity_transform(A, transform_discretize),\n",
    "    ), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb6f78b-2322-4613-b3dd-c933d2c21a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "# https://vincmazet.github.io/bip/histogram/transformations.html\n",
    "# https://www.dsi.unive.it/~bergamasco/teachingfiles/cvslides/2_intensity_transformations.pdf\n",
    "def image_histogram(image):\n",
    "    check_img1chan(image)\n",
    "    hist, _ = numpy.histogram(image, 256)\n",
    "    if hist.ndim != 1: raise ValueError(\"hist.ndim != 1:\")\n",
    "    plot = hist.reshape(-1, 1)/hist.max() < numpy.linspace(0.,1.,256)\n",
    "    plot = numpy.flip(plot, axis=1).T\n",
    "    plot = plot*255\n",
    "    return plot\n",
    "display(image_histogram(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0917c93-74ce-41d1-b903-a1c2064a69b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_equalization(image):\n",
    "    check_img1chan(image)\n",
    "    hist, _ = numpy.histogram(image, 256)\n",
    "    cdf = numpy.cumsum(hist)\n",
    "    return (cdf[image]/image.size*255)\n",
    "display(numpy.concatenate((A, histogram_equalization(A)), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff709201-a154-45b1-a011-3799a50ff35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(numpy.concatenate((image_histogram(A), image_histogram(histogram_equalization(A))), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77fa50e-ab42-4ae0-aed7-59f39443c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/43086557/convolve2d-just-by-using-numpy\n",
    "# TODO: this should take kernel size and a function as argument.\n",
    "def conv2d(image, filt, median=False): # aka local_transform\n",
    "    check_img1chan(image)\n",
    "\n",
    "    if filt.ndim != 2: raise ValueError(\"filt.ndim != 2\")\n",
    "    if filt.shape[0] != filt.shape[1]: raise ValueError(\"filt.shape[0] != filt.shape[1]\")\n",
    "    if filt.shape[0]%2 == 0 or filt.shape[1]%2 == 0: raise ValueError(\"filt.shape[0]%2 == 0 or filt.shape[1]%2 == 0\")\n",
    "\n",
    "    pad = (filt.shape[0]-1)//2\n",
    "    image = numpy.pad(image, (pad,pad), mode='edge')\n",
    "    # TODO: s = tuple(numpy.subtract(image.shape, filt.shape) + 1) + filt.shape i.e. (512, 512, 3, 3)\n",
    "    s = filt.shape + tuple(numpy.subtract(image.shape, filt.shape) + 1)\n",
    "    # TODO: can't this be just a sliding window view?\n",
    "    subM = numpy.lib.stride_tricks.as_strided(image, shape = s, strides = image.strides * 2)\n",
    "    res = subM.reshape(filt.shape[0], filt.shape[1], (image.shape[0]-pad*2)*(image.shape[1]-pad*2))\n",
    "    if not median:\n",
    "        res = (res.transpose((2,0,1))*filt).transpose(1,2,0)\n",
    "        res = numpy.sum(res.reshape(filt.shape[0]*filt.shape[1], (image.shape[0]-pad*2)*(image.shape[1]-pad*2)), axis=0)\n",
    "    else:\n",
    "        res = numpy.median(res.reshape(filt.shape[0]*filt.shape[1], (image.shape[0]-pad*2)*(image.shape[1]-pad*2)), axis=0)\n",
    "    res = res.reshape(image.shape[0]-pad*2, image.shape[1]-pad*2)\n",
    "    # return numpy.einsum('ij,ijkl->kl', filt, subM)\n",
    "    return res\n",
    "\n",
    "def box_kernel(l):\n",
    "    kernel = numpy.ones((l, l))\n",
    "    kernel /= l*l\n",
    "    return kernel\n",
    "\n",
    "#https://stackoverflow.com/a/43346070\n",
    "def gaussian_kernel(l, sigma=1.):\n",
    "    ax = numpy.linspace(-(l - 1) / 2, (l - 1) / 2, l)\n",
    "    gauss = numpy.exp(-0.5 * ax**2 / sigma**2)\n",
    "    kernel = numpy.outer(gauss, gauss)\n",
    "    kernel /= numpy.sum(kernel)\n",
    "    return kernel\n",
    "\n",
    "# TODO: https://www.cs.uoi.gr/~cnikou/Courses/Image_Analysis/01_Linear_Filters.pdf (cool demos)\n",
    "# https://www.cs.toronto.edu/~jepson/csc420/notes/linearFiltering.pdf\n",
    "# https://docs.opencv.org/4.x/d4/d13/tutorial_py_filtering.html\n",
    "display(numpy.concatenate((A, conv2d(A, box_kernel(3)), conv2d(A, gaussian_kernel(9)), conv2d(A, numpy.empty((5,5)), True)), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5ac743-38d7-4cfa-b697-b49279551898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge detection\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Sobel_operator\n",
    "def sobel(image):\n",
    "    check_img1chan(image)\n",
    "    Sx = numpy.array(((+1,0,-1),\n",
    "                      (+2,0,-2),\n",
    "                      (+1,0,-1)))\n",
    "    Sy = Sx.T\n",
    "    image = image.astype(numpy.float64)\n",
    "    Gx = conv2d(image, Sx)\n",
    "    Gy = conv2d(image, Sy)\n",
    "    G = numpy.hypot(Gx, Gy)\n",
    "    Theta = numpy.arctan2(Gx, Gy)\n",
    "    return G\n",
    "# https://en.wikipedia.org/wiki/Prewitt_operator\n",
    "def prewit(image):\n",
    "    check_img1chan(image)\n",
    "    Sx = numpy.array(((+1,0,-1),\n",
    "                      (+1,0,-1),\n",
    "                      (+1,0,-1)))\n",
    "    Sy = Sx.T\n",
    "    image = image.astype(numpy.float64)\n",
    "    Gx = conv2d(image, Sx)\n",
    "    Gy = conv2d(image, Sy)\n",
    "    G = numpy.hypot(Gx, Gy)\n",
    "    Theta = numpy.arctan2(Gx, Gy)\n",
    "    return G\n",
    "# https://en.wikipedia.org/wiki/Roberts_cross\n",
    "def roberts(image):\n",
    "    check_img1chan(image)\n",
    "    # FIXME: requires support for filters with side length even.\n",
    "    Sx = numpy.array(((+1, 0),\n",
    "                      ( 0,-1)))\n",
    "    Sy = numpy.array(((0, +1),\n",
    "                      (-1, 0)))\n",
    "    image = image.astype(numpy.float64)\n",
    "    Gx = conv2d(image, Sx)\n",
    "    Gy = conv2d(image, Sy)\n",
    "    G = numpy.hypot(Gx, Gy)\n",
    "    Theta = numpy.arctan2(Gx, Gy)\n",
    "    return G\n",
    "\n",
    "# TODO: map theta to color in HSI image...\n",
    "# https://en.wikipedia.org/wiki/Canny_edge_detector is a much more complicated algorithm...\n",
    "display(numpy.concatenate((sobel(A), prewit(A)), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887677cd-0c2c-4ec9-8c35-70ae59c72c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = numpy.load('lena_std.npy')\n",
    "# https://tannerhelland.com/2011/10/01/grayscale-image-algorithm-vb6.html\n",
    "def channels_transform(A, T):\n",
    "    check_img3chan(A)\n",
    "    A = A/255\n",
    "    A = A@T\n",
    "    A = A*255\n",
    "    return A\n",
    "luminance = numpy.array((0.2126,0.7152,0.0722))\n",
    "average = numpy.array((1/3,1/3,1/3))\n",
    "\n",
    "# https://leware.net/photo/blogSepia.html\n",
    "sepia = numpy.array((\n",
    "    (0.393, 0.349, 0.272),\n",
    "    (0.769, 0.686, 0.534),\n",
    "    (0.189, 0.168, 0.131),\n",
    "))\n",
    "\n",
    "B = channels_transform(A, luminance)\n",
    "B = numpy.stack((B, B, B), axis=2)\n",
    "C = A[:,:,[2,1,0]] # BGR (just a permutation matrix)\n",
    "D = numpy.clip(channels_transform(A, sepia), 0, 255)\n",
    "display(numpy.concatenate((A,B,C, D), axis=1))\n",
    "# TODO:\n",
    "# https://lisyarus.github.io/blog/posts/transforming-colors-with-matrices.html\n",
    "# https://www.sfu.ca/~jtmulhol/py4math/linalg/ap-image-basics/\n",
    "# https://www.imatest.com/docs/colormatrix/\n",
    "\n",
    "# Other filters http://www.jhlabs.com/ip/filters/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf2cc8-49e1-4072-b403-b20dfd6c56c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://mattlockyer.github.io/iat455/documents/rgb-hsv.pdf\n",
    "# https://faculty.kfupm.edu.sa/ics/lahouari/Teaching/colorspacetransform-1.0.pdf\n",
    "def rgb2hsv(image):\n",
    "    check_img3chan(image)\n",
    "\n",
    "    image_scaled = image/255\n",
    "    R = image_scaled[:,:,0]\n",
    "    G = image_scaled[:,:,1]\n",
    "    B = image_scaled[:,:,2]\n",
    "    \n",
    "    ms_max = numpy.argmax(image_scaled, axis=2)\n",
    "    ms_min = numpy.argmin(image_scaled, axis=2)\n",
    "    deltas = image_scaled.reshape(-1, 3)[0,ms_max.ravel()] - image_scaled.reshape(-1, 3)[0,ms_min.ravel()]\n",
    "    deltas = deltas.reshape(image.shape[0], image.shape[1])\n",
    "    if numpy.isclose(deltas, 0.0).any(): return ValueError(\"numpy.isclose(delta, 0.0).any()\")\n",
    "\n",
    "    hue = numpy.stack((G-B, B-R, R-G), axis=2).transpose((2,0,1))/deltas\n",
    "    hue = hue.transpose((1,2,0)) + numpy.array((0.,2.,4.))\n",
    "    hue = hue.reshape(-1,3)[0,ms_max].reshape(image.shape[0], image.shape[1])\n",
    "    hue = (hue*255).astype(numpy.uint8)\n",
    "\n",
    "    value = (ms_max*255)\n",
    "\n",
    "    saturation = numpy.divide(deltas, value, out=numpy.zeros_like(deltas), where=value!=0)\n",
    "    saturation = (saturation*255).astype(numpy.uint8)\n",
    "    return numpy.stack((hue, saturation, value), axis=2)\n",
    "\n",
    "def hsv2rgb(image):\n",
    "    check_img3chan(image)\n",
    "\n",
    "    H = image[:,:,0]%6\n",
    "    S = image[:,:,1]/255\n",
    "    V = image[:,:,2]/255\n",
    "\n",
    "    alphas = V*(1-S)\n",
    "    beta = 0\n",
    "    gamma = 0\n",
    "    \n",
    "    pass\n",
    "\n",
    "B = rgb2hsv(A)\n",
    "B[:,:,0]%6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538524ca-c611-42cc-830f-ed946947f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian pyramid https://www.youtube.com/watch?v=U7qa7i0K9C4\n",
    "# Anti-aliasing (signal sampling) https://www.youtube.com/watch?v=fTJjPGaPsq4\n",
    "# Template matching with cross-correlation (no SIFT) https://www.youtube.com/watch?v=EO1-MCWfXCU\n",
    "# Blur filter and convoltion theorem https://www.youtube.com/watch?v=xvDeFABiwrg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
